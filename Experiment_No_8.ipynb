{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW2xNXbyV6u4qd+QOMn/1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MussaddikKhan/Data-Science-College-Practicals-/blob/main/Experiment_No_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experiment – 8**  \n",
        "**Date:**  \n",
        "**Roll No.: 24201013**  \n",
        "**Title:** *Logistic Regression using Wrapper Selection (Recursive Feature Elimination)*\n",
        "\n",
        "---\n",
        "\n",
        "## **Theory**\n",
        "\n",
        "### **Logistic Regression (Introduction)**  \n",
        "Logistic Regression is a supervised classification algorithm used to predict **binary outcomes** (0 or 1).  \n",
        "Instead of predicting continuous values, it predicts the **probability** that an input belongs to a certain class.  \n",
        "\n",
        "The model uses the **sigmoid function**:\n",
        "\n",
        "<br>\n",
        "\n",
        "$$\n",
        "P(y = 1 \\mid x)=\\frac{1}{1 + e^{-(b_0+b_1x_1+b_2x_2+\\dots +b_nx_n)}}\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Decision Rule**\n",
        "- If probability ≥ 0.5 → **Class 1**  \n",
        "- If probability < 0.5 → **Class 0**\n",
        "\n",
        "---\n",
        "\n",
        "## **Feature Selection – Wrapper Method**\n",
        "\n",
        "Wrapper methods repeatedly train the model and evaluate performance to choose the best subset of features.\n",
        "\n",
        "### **Steps**\n",
        "1. Train model on selected features  \n",
        "2. Evaluate accuracy  \n",
        "3. Add/remove features  \n",
        "4. Select feature subset that gives highest accuracy  \n",
        "\n",
        "---\n",
        "\n",
        "## **Recursive Feature Elimination (RFE)**\n",
        "\n",
        "RFE is a **backward elimination** technique.\n",
        "\n",
        "### **How RFE Works**\n",
        "1. Train Logistic Regression model on **all features**  \n",
        "2. Check feature importance (coefficients)  \n",
        "3. Remove the **least important feature**  \n",
        "4. Repeat until only required number of features remain  \n",
        "\n",
        "---\n",
        "\n",
        "## **Advantages**\n",
        "- Improves model accuracy  \n",
        "- Reduces overfitting  \n",
        "- Works well on small and medium datasets  \n",
        "\n",
        "## **Disadvantages**\n",
        "- Computationally expensive  \n",
        "- Performance depends on dataset quality  \n",
        "- Not ideal if dataset has too much noise  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "KXcAw-eGZu-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0SzfpjcmZuII",
        "outputId": "5538d12f-d606-4183-a144-f8ca19aac758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy with selected features: 0.8367\n",
            "Selected Features Mask:\n",
            " [False  True  True  True False False False  True False False False  True\n",
            " False False  True  True  True  True  True False]\n",
            "Feature Ranking:\n",
            " [ 4  1  1  1  6  2 11  1  8 10  7  1  3  9  1  1  1  1  1  5]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ---------------------------------------\n",
        "# Step 1: Create synthetic dataset\n",
        "# ---------------------------------------\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=20,\n",
        "    n_informative=10,\n",
        "    n_redundant=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# Step 2: Train-Test Split\n",
        "# ---------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# Step 3: Standardize the Data\n",
        "# ---------------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------------------\n",
        "# Step 4: Initialize Logistic Regression\n",
        "# ---------------------------------------\n",
        "estimator = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# ---------------------------------------\n",
        "# Step 5: Apply RFE (Recursive Feature Elimination)\n",
        "# ---------------------------------------\n",
        "selector = RFE(estimator=estimator, n_features_to_select=10, step=1)\n",
        "selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Transform data using selected features\n",
        "X_train_selected = selector.transform(X_train_scaled)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# ---------------------------------------\n",
        "# Step 6: Train Final Model\n",
        "# ---------------------------------------\n",
        "final_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "final_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# ---------------------------------------\n",
        "# Step 7: Evaluate\n",
        "# ---------------------------------------\n",
        "accuracy = final_model.score(X_test_selected, y_test)\n",
        "print(f\"Model accuracy with selected features: {accuracy:.4f}\")\n",
        "\n",
        "# Feature selection details\n",
        "print(\"Selected Features Mask:\\n\", selector.support_)\n",
        "print(\"Feature Ranking:\\n\", selector.ranking_)\n"
      ]
    }
  ]
}